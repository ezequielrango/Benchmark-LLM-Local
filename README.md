# Benchmark-LLM-Local
App interactiva con Streamlit para benchmarks locales de modelos LLM vía Ollama. Mide rendimiento, velocidad, latencia y uso de recursos (CPU, RAM, swap). Incluye comparativas, gráficos, exportación CSV y conclusión automática para elegir el modelo óptimo. Cross-OS.
